<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>积雪筱草的Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="搬砖人">
<meta property="og:type" content="website">
<meta property="og:title" content="积雪筱草的Blog">
<meta property="og:url" content="https://mohuani.github.io/page/9/index.html">
<meta property="og:site_name" content="积雪筱草的Blog">
<meta property="og:description" content="搬砖人">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="mohuani">
<meta property="article:tag" content="Bug工程师">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="积雪筱草的Blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">积雪筱草的Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">流水账</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://mohuani.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-数据库/MySQL/深入理解 Mysql 索引底层原理" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20Mysql%20%E7%B4%A2%E5%BC%95%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20Mysql%20%E7%B4%A2%E5%BC%95%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/">深入理解 Mysql 索引底层原理</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>深入理解 Mysql 索引底层原理 - <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/113917726">https://zhuanlan.zhihu.com/p/113917726</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20Mysql%20%E7%B4%A2%E5%BC%95%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/" data-id="ckmujocnn00282vrs1i28aebt" data-title="深入理解 Mysql 索引底层原理" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-数据库/Redis/Redis 高可用解决方案总结" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%20%E9%AB%98%E5%8F%AF%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%20%E9%AB%98%E5%8F%AF%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/">Redis 高可用解决方案总结</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Redis 高可用解决方案总结：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247487221&amp;idx=1&amp;sn=1c3182ad46e8781a04f49ec8ad53f482&amp;chksm=eb538bc3dc2402d5df24a37ec0c0c31099d152df6d3b62380ccebf7f4ec04e64a8dadd83fd7b&amp;mpshare=1&amp;scene=24&amp;srcid=05031WU0aEvCwiVHBCld65XU&amp;key=bf4cf7f356eb2752d8a578bd21d61203d7e72957a4125eb1fe25f0b2384de21e8c81b4a3811eb1285d479714fea7aaa1aa4249cb83cdd5c96b083e77b1c3747440db1862d7b543a903029fb6330afa7a&amp;ascene=14&amp;uin=MTkwNjk4NjAxMA==&amp;devicetype=Windows+10&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=JogDaVDjKXx9W3zQZ2sl6TAUdMDS7rKA0Zb9hMwwVMC4ALxeAySdvq8JADMCeINW">https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;mid=2247487221&amp;idx=1&amp;sn=1c3182ad46e8781a04f49ec8ad53f482&amp;chksm=eb538bc3dc2402d5df24a37ec0c0c31099d152df6d3b62380ccebf7f4ec04e64a8dadd83fd7b&amp;mpshare=1&amp;scene=24&amp;srcid=05031WU0aEvCwiVHBCld65XU&amp;key=bf4cf7f356eb2752d8a578bd21d61203d7e72957a4125eb1fe25f0b2384de21e8c81b4a3811eb1285d479714fea7aaa1aa4249cb83cdd5c96b083e77b1c3747440db1862d7b543a903029fb6330afa7a&amp;ascene=14&amp;uin=MTkwNjk4NjAxMA%3D%3D&amp;devicetype=Windows+10&amp;version=62060833&amp;lang=zh_CN&amp;pass_ticket=JogDaVDjKXx9W3zQZ2sl6TAUdMDS7rKA0Zb9hMwwVMC4ALxeAySdvq8JADMCeINW</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%20%E9%AB%98%E5%8F%AF%E7%94%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/" data-id="ckmujocno00292vrs8xtjbhbr" data-title="Redis 高可用解决方案总结" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-数据库/Redis/redis-list" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/redis-list/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/redis-list/">redis-list</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <ul>
<li>控制List的长度，每次push或者pop的时候，可以使用ltrim()函数让list保持固定长度</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/redis-list/" data-id="ckmujocno002a2vrshw1rdjak" data-title="redis-list" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算相关/HTTP/HTTP 返回码详解" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/HTTP/HTTP%20%E8%BF%94%E5%9B%9E%E7%A0%81%E8%AF%A6%E8%A7%A3/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/HTTP/HTTP%20%E8%BF%94%E5%9B%9E%E7%A0%81%E8%AF%A6%E8%A7%A3/">HTTP 返回码详解</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p> HTTP状态码（HTTP Status Code）是用以表示网页服务器HTTP响应状态的3位数字代码。它由 RFC 2616 规范定义的，并得到RFC 2518、RFC 2817、RFC 2295、RFC 2774、RFC 4918等规范扩展。</p>
<p>##1xx（临时响应）<br><strong>表示临时响应并需要请求者继续执行操作的状态代码。</strong></p>
<ul>
<li>100（继续）请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。  </li>
<li>101（切换协议）请求者已要求服务器切换协议，服务器已确认并准备切换。</li>
</ul>
<p>##2xx （成功）<br><strong>表示成功处理了请求的状态代码。</strong></p>
<ul>
<li><p>200（成功）服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。</p>
</li>
<li><p>201（已创建）请求成功并且服务器创建了新的资源。</p>
</li>
<li><p>202（已接受） 服务器已接受请求，但尚未处理。</p>
</li>
<li><p>203（非授权信息）服务器已成功处理了请求，但返回的信息可能来自另一来源。</p>
</li>
<li><p>204（无内容）服务器成功处理了请求，但没有返回任何内容。</p>
</li>
<li><p>205（重置内容）服务器成功处理了请求，但没有返回任何内容。</p>
</li>
<li><p>206（部分内容）服务器成功处理了部分 GET 请求。</p>
</li>
</ul>
<p>##3xx （重定向）<br><strong>表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。</strong></p>
<ul>
<li><p>300（多种选择）针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。</p>
</li>
<li><p>301（永久移动）请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。</p>
</li>
<li><p>302（临时移动）服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</p>
</li>
<li><p>303（查看其他位置）请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。</p>
</li>
<li><p>304（未修改）自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。</p>
</li>
<li><p>305（使用代理）请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。</p>
</li>
<li><p>307（临时重定向）服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</p>
</li>
</ul>
<p>##4xx（请求错误）<br><strong>这些状态代码表示请求可能出错，妨碍了服务器的处理。</strong></p>
<ul>
<li><p>400（错误请求）服务器不理解请求的语法。</p>
</li>
<li><p>401（未授权）请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。</p>
</li>
<li><p>403（禁止）服务器拒绝请求。</p>
</li>
<li><p>404（未找到）服务器找不到请求的网页。</p>
</li>
<li><p>405（方法禁用）禁用请求中指定的方法。</p>
</li>
<li><p>406（不接受）无法使用请求的内容特性响应请求的网页。</p>
</li>
<li><p>407（需要代理授权）此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。</p>
</li>
<li><p>408（请求超时）服务器等候请求时发生超时。</p>
</li>
<li><p>409（冲突）服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。</p>
</li>
<li><p>410（已删除）如果请求的资源已永久删除，服务器就会返回此响应。</p>
</li>
<li><p>411（需要有效长度）服务器不接受不含有效内容长度标头字段的请求。</p>
</li>
<li><p>412（未满足前提条件）服务器未满足请求者在请求中设置的其中一个前提条件。</p>
</li>
<li><p>413（请求实体过大）服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。</p>
</li>
<li><p>414（请求的 URI 过长）请求的 URI（通常为网址）过长，服务器无法处理。</p>
</li>
<li><p>415（不支持的媒体类型）请求的格式不受请求页面的支持。</p>
</li>
<li><p>416（请求范围不符合要求）如果页面无法提供请求的范围，则服务器会返回此状态代码。</p>
</li>
<li><p>417（未满足期望值）服务器未满足”期望”请求标头字段的要求。</p>
</li>
</ul>
<p>##5xx（服务器错误）<br><strong>这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。</strong></p>
<ul>
<li>500（服务器内部错误）服务器遇到错误，无法完成请求。</li>
</ul>
<p>501（尚未实施）服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。</p>
<ul>
<li><p>502（错误网关）服务器作为网关或代理，从上游服务器收到无效响应。</p>
</li>
<li><p>503（服务不可用）服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。</p>
</li>
<li><p>504（网关超时）服务器作为网关或代理，但是没有及时从上游服务器收到请求。</p>
</li>
<li><p>505（HTTP 版本不受支持）服务器不支持请求中所用的 HTTP 协议版本。</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/HTTP/HTTP%20%E8%BF%94%E5%9B%9E%E7%A0%81%E8%AF%A6%E8%A7%A3/" data-id="ckmujocnp002b2vrs8g0a75i5" data-title="HTTP 返回码详解" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算相关/HTTP/HTTPS 比 HTTP 更安全" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/HTTP/HTTPS%20%E6%AF%94%20HTTP%20%E6%9B%B4%E5%AE%89%E5%85%A8/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/HTTP/HTTPS%20%E6%AF%94%20HTTP%20%E6%9B%B4%E5%AE%89%E5%85%A8/">HTTPS 比 HTTP 更安全</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>为什么 HTTPS 比 HTTP 更安全？：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/xAXiY_7Lvog-Xrq6qEokUQ?client=tim&amp;ADUIN=1348954449&amp;ADSESSION=1561252296&amp;ADTAG=CLIENT.QQ.5603_.0&amp;ADPUBNO=26882">https://mp.weixin.qq.com/s/xAXiY_7Lvog-Xrq6qEokUQ?client=tim&amp;ADUIN=1348954449&amp;ADSESSION=1561252296&amp;ADTAG=CLIENT.QQ.5603_.0&amp;ADPUBNO=26882</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/HTTP/HTTPS%20%E6%AF%94%20HTTP%20%E6%9B%B4%E5%AE%89%E5%85%A8/" data-id="ckmujocnq002c2vrs6llp5ez8" data-title="HTTPS 比 HTTP 更安全" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算相关/TensorFlow/TensorFlow学习笔记(一)" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/">TensorFlow学习笔记1</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>自己构建一些数据，来实现一个简单函数的模拟学习</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># create data</span><br><span class="line">x_data &#x3D; np.random.rand(100).astype(np.float32)</span><br><span class="line">y_data &#x3D; x_data*0.1 + 0.3</span><br><span class="line"></span><br><span class="line"># create tensorflow structure start</span><br><span class="line">Weights &#x3D; tf.Variable(tf.random_uniform([1],-1,0))</span><br><span class="line">biases &#x3D; tf.Variable(tf.zeros([1]))</span><br><span class="line"></span><br><span class="line">y &#x3D; Weights*x_data + biases</span><br><span class="line"></span><br><span class="line">loss &#x3D; tf.reduce_mean(tf.square(y-y_data))</span><br><span class="line">optimizer &#x3D; tf.train.GradientDescentOptimizer(0.5)</span><br><span class="line">train &#x3D; optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"># 2018-4-6记录</span><br><span class="line"># 莫烦的视频中用的是老版本 initialize_all_variables()</span><br><span class="line"># 现在新版的函数是 global_variables_initializer()</span><br><span class="line"># init &#x3D; tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">init &#x3D; tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"># create tensorflow structure end</span><br><span class="line"></span><br><span class="line">sess &#x3D; tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line">for step in range(401):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    if step % 20 &#x3D;&#x3D; 0:</span><br><span class="line">        print(step,sess.run(Weights),sess.run(biases))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>经过401的迭代后输出的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">0 [-0.39455852] [0.70643663]</span><br><span class="line">20 [-0.05729461] [0.37692836]</span><br><span class="line">40 [0.05577959] [0.32162696]</span><br><span class="line">60 [0.08756826] [0.30608]</span><br><span class="line">80 [0.09650504] [0.3017093]</span><br><span class="line">100 [0.09901748] [0.30048054]</span><br><span class="line">120 [0.09972379] [0.3001351]</span><br><span class="line">140 [0.09992234] [0.300038]</span><br><span class="line">160 [0.09997816] [0.30001068]</span><br><span class="line">180 [0.09999388] [0.30000302]</span><br><span class="line">200 [0.09999828] [0.30000085]</span><br><span class="line">220 [0.09999953] [0.30000025]</span><br><span class="line">240 [0.09999986] [0.30000007]</span><br><span class="line">260 [0.0999999] [0.30000007]</span><br><span class="line">280 [0.0999999] [0.30000007]</span><br><span class="line">300 [0.0999999] [0.30000007]</span><br><span class="line">320 [0.0999999] [0.30000007]</span><br><span class="line">340 [0.0999999] [0.30000007]</span><br><span class="line">360 [0.0999999] [0.30000007]</span><br><span class="line">380 [0.0999999] [0.30000007]</span><br><span class="line">400 [0.0999999] [0.30000007]</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/" data-id="ckmujocnr002d2vrs95x4h5q2" data-title="TensorFlow学习笔记1" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算相关/TensorFlow/TensorFlow学习笔记(二)" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/">TensorFlow学习笔记2</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><strong>Session的两种使用方式</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">matrix1 &#x3D; tf.constant([[3,3]])</span><br><span class="line">matrix2 &#x3D; tf.constant([[2,2]])</span><br><span class="line"></span><br><span class="line">product &#x3D; tf.matmul(matrix1,matrix2)  # matrix multiply  np.dot(m1,m2)</span><br><span class="line"></span><br><span class="line"># session的两种打开模式</span><br><span class="line"></span><br><span class="line"># method 1</span><br><span class="line"></span><br><span class="line"># sess &#x3D; tf.Session()</span><br><span class="line"># result1 &#x3D; sess.run(product)</span><br><span class="line"># print(result1)</span><br><span class="line"># sess.close()</span><br><span class="line"></span><br><span class="line"># method 2</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    result2 &#x3D; sess.run(product)</span><br><span class="line">    print(result2)</span><br></pre></td></tr></table></figure>

<p>运行的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[12]]</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/" data-id="ckmujocns002e2vrs2r3168sp" data-title="TensorFlow学习笔记2" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算相关/TensorFlow/TensorFlow学习笔记（三）" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/">TensorFlow学习笔记3</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><strong>Variable变量的简单使用</strong></p>
<p>在 Tensorflow 中，定义了某字符串是变量，它才是变量，这一点是与 Python 所不同的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">state &#x3D; tf.Variable(0,name &#x3D; &#39;counter&#39;)</span><br><span class="line">print(state.name)</span><br><span class="line"></span><br><span class="line">one &#x3D; tf.constant(1)</span><br><span class="line"></span><br><span class="line">new_vaule &#x3D; tf.add(state,one)</span><br><span class="line">update &#x3D; tf.assign(state,new_vaule)</span><br><span class="line"></span><br><span class="line"># 2018-4-6记录</span><br><span class="line"># 莫烦的视频中用的是老版本 initialize_all_variables()</span><br><span class="line"># 现在新版的函数是 global_variables_initializer()</span><br><span class="line"># init &#x3D; tf.initialize_all_variables()</span><br><span class="line">init &#x3D; tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sess &#x3D; tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line">for _ in range(3):</span><br><span class="line">    sess.run(update)</span><br><span class="line">    print(sess.run(state))</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>

<p>运行的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">counter:0</span><br><span class="line"></span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/" data-id="ckmujocnt002f2vrsdc22eimy" data-title="TensorFlow学习笔记3" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算相关/TensorFlow/TensorFlow学习笔记（五）" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/">TensorFlow学习笔记5</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <ol>
<li>搭建神经网络基本流程</li>
</ol>
<hr>
<p>定义添加神经层的函数</p>
<p>1.训练的数据<br>2.定义节点准备接收数据<br>3.定义神经层：隐藏层和预测层<br>4.定义 loss 表达式<br>5.选择 optimizer 使 loss 达到最小</p>
<p>然后对所有变量进行初始化，通过 sess.run optimizer，迭代 1000 次进行学习：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 添加层</span><br><span class="line">def add_layer(inputs, in_size, out_size, activation_function&#x3D;None):</span><br><span class="line">    # add one more layer and return the output of this layer</span><br><span class="line">    Weights &#x3D; tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases &#x3D; tf.Variable(tf.zeros([1, out_size]) + 0.1)</span><br><span class="line">    Wx_plus_b &#x3D; tf.matmul(inputs, Weights) + biases</span><br><span class="line">    if activation_function is None:</span><br><span class="line">        outputs &#x3D; Wx_plus_b</span><br><span class="line">    else:</span><br><span class="line">        outputs &#x3D; activation_function(Wx_plus_b)</span><br><span class="line">    return outputs</span><br><span class="line"></span><br><span class="line"># 1.训练的数据</span><br><span class="line"># Make up some real data</span><br><span class="line">x_data &#x3D; np.linspace(-1,1,300)[:, np.newaxis]</span><br><span class="line">noise &#x3D; np.random.normal(0, 0.05, x_data.shape)</span><br><span class="line">y_data &#x3D; np.square(x_data) - 0.5 + noise</span><br><span class="line"></span><br><span class="line"># 2.定义节点准备接收数据</span><br><span class="line"># define placeholder for inputs to network</span><br><span class="line">xs &#x3D; tf.placeholder(tf.float32, [None, 1])</span><br><span class="line">ys &#x3D; tf.placeholder(tf.float32, [None, 1])</span><br><span class="line"></span><br><span class="line"># 3.定义神经层：隐藏层和预测层</span><br><span class="line"># add hidden layer 输入值是 xs，在隐藏层有 10 个神经元</span><br><span class="line">l1 &#x3D; add_layer(xs, 1, 10, activation_function&#x3D;tf.nn.relu)</span><br><span class="line"># add output layer 输入值是隐藏层 l1，在预测层输出 1 个结果</span><br><span class="line">prediction &#x3D; add_layer(l1, 10, 1, activation_function&#x3D;None)</span><br><span class="line"></span><br><span class="line"># 4.定义 loss 表达式</span><br><span class="line"># the error between prediciton and real data</span><br><span class="line">loss &#x3D; tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),</span><br><span class="line">                     reduction_indices&#x3D;[1]))</span><br><span class="line"></span><br><span class="line"># 5.选择 optimizer 使 loss 达到最小</span><br><span class="line"># 这一行定义了用什么方式去减少 loss，学习率是 0.1</span><br><span class="line">train_step &#x3D; tf.train.GradientDescentOptimizer(0.1).minimize(loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># important step 对所有变量进行初始化</span><br><span class="line">#init &#x3D; tf.initialize_all_variables()</span><br><span class="line">init &#x3D; tf.global_variables_initializer()</span><br><span class="line">sess &#x3D; tf.Session()</span><br><span class="line"># 上面定义的都没有运算，直到 sess.run 才会开始运算</span><br><span class="line"></span><br><span class="line"> 1. 列表内容</span><br><span class="line"></span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"># 迭代 1000 次学习，sess.run optimizer</span><br><span class="line">for i in range(1000):</span><br><span class="line">    # training train_step 和 loss 都是由 placeholder 定义的运算，所以这里要用 feed 传入参数</span><br><span class="line">    sess.run(train_step, feed_dict&#x3D;&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line">    if i % 50 &#x3D;&#x3D; 0:</span><br><span class="line">        # to see the step improvement</span><br><span class="line">        print(sess.run(loss, feed_dict&#x3D;&#123;xs: x_data, ys: y_data&#125;))</span><br></pre></td></tr></table></figure>

<p>运行的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">0.005811795</span><br><span class="line">0.005243601</span><br><span class="line">0.0048823874</span><br><span class="line">0.004609399</span><br><span class="line">0.0043644696</span><br><span class="line">0.00416661</span><br><span class="line">0.004008478</span><br><span class="line">0.0038800447</span><br><span class="line">0.0037535445</span><br><span class="line">0.0036441346</span><br><span class="line">0.003548924</span><br><span class="line">0.0034721296</span><br><span class="line">0.003409828</span><br><span class="line">0.0033587494</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/" data-id="ckmujocnu002g2vrs2wtq0kf2" data-title="TensorFlow学习笔记5" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-计算相关/TensorFlow/TensorFlow学习笔记（六）" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T11:36:38.000Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/">TensorFlow学习笔记6</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="TensorFlow搭建神经网络可视化结果"><a href="#TensorFlow搭建神经网络可视化结果" class="headerlink" title="TensorFlow搭建神经网络可视化结果"></a>TensorFlow搭建神经网络可视化结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">def add_layer(inputs, in_size, out_size, activation_function &#x3D; None):</span><br><span class="line">    Weights &#x3D; tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases &#x3D; tf.Variable(tf.zeros([1, out_size]) + 0.1)</span><br><span class="line">    Wx_plus_b &#x3D; tf.matmul(inputs, Weights) + biases</span><br><span class="line">    if activation_function is None:</span><br><span class="line">        outputs &#x3D; Wx_plus_b</span><br><span class="line">    else:</span><br><span class="line">        outputs &#x3D; activation_function(Wx_plus_b)</span><br><span class="line">    return outputs</span><br><span class="line"></span><br><span class="line">x_data &#x3D; np.linspace(-1,1,300)[:,np.newaxis]</span><br><span class="line">noise &#x3D; np.random.normal(0,0.05,x_data.shape)</span><br><span class="line">y_data &#x3D; np.square(x_data) - 0.5 + noise</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">xs &#x3D; tf.placeholder(tf.float32,[None,1])</span><br><span class="line">ys &#x3D; tf.placeholder(tf.float32,[None,1])</span><br><span class="line">l1 &#x3D; add_layer(xs,1,10,activation_function &#x3D; tf.nn.relu)</span><br><span class="line">prediction &#x3D; add_layer(l1,10,1,activation_function&#x3D;None)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loss &#x3D;tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),</span><br><span class="line">                    reduction_indices&#x3D;[1]))</span><br><span class="line"></span><br><span class="line">train_step &#x3D; tf.train.GradientDescentOptimizer(0.1).minimize(loss)</span><br><span class="line"></span><br><span class="line"># init &#x3D; tf.initialize_all_variables()</span><br><span class="line">init &#x3D; tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">sess &#x3D; tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line">fig &#x3D; plt.figure()</span><br><span class="line">ax &#x3D; fig.add_subplot(1,1,1)</span><br><span class="line">ax.scatter(x_data,y_data)</span><br><span class="line"></span><br><span class="line">plt.ion()</span><br><span class="line">plt.show()</span><br><span class="line"># plt.close()</span><br><span class="line"></span><br><span class="line">for i in range(1000):</span><br><span class="line">    sess.run(train_step,feed_dict&#x3D;&#123;xs:x_data,ys:y_data&#125;)</span><br><span class="line">    if i % 50 &#x3D;&#x3D; 0:</span><br><span class="line">        # print(sess.run(loss,feed_dict&#x3D;&#123;xs:x_data,ys:y_data&#125;))</span><br><span class="line"></span><br><span class="line">        try:</span><br><span class="line">            ax.lines.remove(lines[0])</span><br><span class="line">        except Exception:</span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">        prediction_value &#x3D; sess.run(prediction,feed_dict&#x3D;&#123;xs:x_data&#125;)</span><br><span class="line">        lines &#x3D; ax.plot(x_data,prediction_value,&#39;r-&#39;,lw &#x3D; 3)</span><br><span class="line">        plt.pause(0.5)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行的效果<br><img src="https://img-blog.csdn.net/20180407000723874?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dmazI5NzUwMTk2NzE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://mohuani.github.io/2021/03/24/%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3/TensorFlow/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/" data-id="ckmujocnv002h2vrs5q2vhwhv" data-title="TensorFlow学习笔记6" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/8/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/10/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/03/30/%E8%BF%90%E7%BB%B4/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/">mac环境变量</a>
          </li>
        
          <li>
            <a href="/2021/03/29/Git/Git%20Commit%20Template/">Git Commit Template</a>
          </li>
        
          <li>
            <a href="/2021/03/29/Git/git%20submoudle/">git submoudle</a>
          </li>
        
          <li>
            <a href="/2021/03/24/Golang/5G%E6%97%B6%E4%BB%A3Vlog%E5%8E%9F%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91/">5G时代Vlog原型系统开发</a>
          </li>
        
          <li>
            <a href="/2021/03/24/Git/gitignore%E6%96%87%E4%BB%B6%E4%B8%8D%E7%94%9F%E6%95%88/">gitignore文件不生效</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 mohuani<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>